{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import run_binary_classifier\n",
    "import run_multilabel_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary = os.path.join('../', 'data/train_binary.csv')\n",
    "test_binary = os.path.join('../', 'data/test_clean_binary.csv')\n",
    "\n",
    "train_multilabel = os.path.join('../', 'data/train.csv')\n",
    "test_multilabel = os.path.join('../', 'data/test_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_param_grid = {\n",
    "        'bag_of_words__stop_words': ['english'],\n",
    "        'bag_of_words__ngram_range': [(1, 2)],\n",
    "        'bag_of_words__max_features': [500],\n",
    "        'dim_reduct__n_components': [300],\n",
    "        'normalizer__norm': ['l2'],\n",
    "        'classifier__C': [5., 10.]\n",
    "}\n",
    "\n",
    "\n",
    "multilabel_param_grid  = [{\n",
    "        'estimator__bag_of_words__stop_words': ['english'],\n",
    "        'estimator__bag_of_words__ngram_range': [(1, 2)],\n",
    "        'estimator__bag_of_words__max_features': [500],\n",
    "        'estimator__dim_reduct__n_components': [300],\n",
    "        'estimator__normalizer__norm': ['l2'],\n",
    "        'estimator__classifier__C': [5., 10.]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.75      0.77        16\n",
      "          1       0.73      0.79      0.76        14\n",
      "\n",
      "avg / total       0.77      0.77      0.77        30\n",
      "\n",
      "'=================     Best parameters     ================='\n",
      "{'bag_of_words__max_features': 500, 'bag_of_words__ngram_range': (1, 2), 'bag_of_words__stop_words': 'english', 'classifier__C': 10.0, 'dim_reduct__n_components': 300, 'normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "binary_clf = run_binary_classifier.run(binary_param_grid, LogisticRegression(), comments_file=train_binary)\n",
    "\n",
    "with open('./saved_models/log_reg_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.00      0.00      0.00         3\n",
      "          2       0.80      0.44      0.57        18\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.42      0.45      0.43        11\n",
      "          5       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.78      0.68      0.72        63\n",
      "\n",
      "=================     Best parameters     =================\n",
      "{'estimator__bag_of_words__max_features': 500,\n",
      " 'estimator__bag_of_words__ngram_range': (1, 2),\n",
      " 'estimator__bag_of_words__stop_words': 'english',\n",
      " 'estimator__classifier__C': 5.0,\n",
      " 'estimator__dim_reduct__n_components': 300,\n",
      " 'estimator__normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.0s finished\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "multilabel_clf = run_multilabel_classifier.run(multilabel_param_grid, LogisticRegression(), comments_file=train_multilabel)\n",
    "with open('./saved_models/log_reg_joint_multilabel.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.86      0.77        50\n",
      "          1       0.82      0.62      0.70        50\n",
      "\n",
      "avg / total       0.75      0.74      0.74       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_binary_test, y_binary_test = run_binary_classifier.load_comments(test_binary)\n",
    "y_binary_test_predict = binary_clf.predict(X_binary_test)\n",
    "\n",
    "print(classification_report(y_binary_test, y_binary_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       100\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.80      0.40      0.53        70\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.63      0.39      0.48        56\n",
      "          5       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.76      0.60      0.66       251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_multilabel_test, y_multilabel_test = run_multilabel_classifier.load_comments(test_multilabel)\n",
    "y_multilabel_test_predict = multilabel_clf.predict(X_multilabel_test)\n",
    "\n",
    "print(classification_report(y_multilabel_test, y_multilabel_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final joint prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.38      0.55       100\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       0.75      0.13      0.22        70\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.53      0.14      0.23        56\n",
      "          5       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.73      0.22      0.33       251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "final_predictions = np.full_like(y_multilabel_test_predict, -1)\n",
    "\n",
    "\n",
    "non_toxic_indices = np.argwhere(y_binary_test_predict == 0).flatten()\n",
    "toxic_indices = np.argwhere(y_binary_test_predict == 1).flatten()\n",
    "\n",
    "# place binary classifier's prediction of clean comments\n",
    "final_predictions[non_toxic_indices] = np.array([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "multilabel_toxic_predictions = y_multilabel_test_predict[toxic_indices]\n",
    "final_predictions[toxic_indices] = multilabel_toxic_predictions\n",
    "\n",
    "print(classification_report(y_multilabel_test, final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_param_grid = {\n",
    "        'bag_of_words__stop_words': ['english'],\n",
    "        'bag_of_words__ngram_range': [(1, 2)],\n",
    "        'bag_of_words__max_features': [500],\n",
    "        'dim_reduct__n_components': [300],\n",
    "        'normalizer__norm': ['l2'],\n",
    "        'classifier__alpha': [1.0],\n",
    "        'classifier__binarize': [0.0]\n",
    "}\n",
    "\n",
    "multilabel_param_grid = [{\n",
    "        'estimator__bag_of_words__stop_words': ['english'],\n",
    "        'estimator__bag_of_words__ngram_range': [(1, 2)],\n",
    "        'estimator__bag_of_words__max_features': [500],\n",
    "        'estimator__dim_reduct__n_components': [300],\n",
    "        'estimator__normalizer__norm': ['l2'],\n",
    "        'estimator__classifier__alpha': [1.0],\n",
    "        'estimator__classifier__binarize': [0.0]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.73      0.71        15\n",
      "          1       0.71      0.67      0.69        15\n",
      "\n",
      "avg / total       0.70      0.70      0.70        30\n",
      "\n",
      "'=================     Best parameters     ================='\n",
      "{'bag_of_words__max_features': 500, 'bag_of_words__ngram_range': (1, 2), 'bag_of_words__stop_words': 'english', 'classifier__alpha': 1.0, 'classifier__binarize': 0.0, 'dim_reduct__n_components': 300, 'normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "binary_clf = run_binary_classifier.run(binary_param_grid, BernoulliNB(), comments_file=train_binary)\n",
    "\n",
    "with open('./saved_models/naiveB_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.33      0.25      0.29         4\n",
      "          2       0.52      0.92      0.67        13\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.52      0.87      0.65        15\n",
      "          5       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.72      0.88      0.77        64\n",
      "\n",
      "=================     Best parameters     =================\n",
      "{'estimator__bag_of_words__max_features': 500,\n",
      " 'estimator__bag_of_words__ngram_range': (1, 2),\n",
      " 'estimator__bag_of_words__stop_words': 'english',\n",
      " 'estimator__classifier__alpha': 1.0,\n",
      " 'estimator__classifier__binarize': 0.0,\n",
      " 'estimator__dim_reduct__n_components': 300,\n",
      " 'estimator__normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "multilabel_clf = run_multilabel_classifier.run(multilabel_param_grid, BernoulliNB(), comments_file=train_multilabel)\n",
    "with open('./saved_models/naiveB_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.45      0.55        51\n",
      "          1       0.59      0.82      0.68        49\n",
      "\n",
      "avg / total       0.65      0.63      0.62       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_binary_test, y_binary_test = run_binary_classifier.load_comments(test_binary)\n",
    "y_binary_test_predict = binary_clf.predict(X_binary_test)\n",
    "\n",
    "print(classification_report(y_binary_test, y_binary_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       100\n",
      "          1       0.00      0.00      0.00         3\n",
      "          2       0.63      0.75      0.69        64\n",
      "          3       0.33      0.33      0.33         3\n",
      "          4       0.59      0.77      0.67        57\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.73      0.81      0.77       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_multilabel_test, y_multilabel_test = run_multilabel_classifier.load_comments(test_multilabel)\n",
    "y_multilabel_test_predict = multilabel_clf.predict(X_multilabel_test)\n",
    "\n",
    "print(classification_report(y_multilabel_test, y_multilabel_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final joint prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.68      0.81       100\n",
      "          1       0.00      0.00      0.00         3\n",
      "          2       0.64      0.56      0.60        64\n",
      "          3       0.50      0.33      0.40         3\n",
      "          4       0.62      0.61      0.62        57\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.75      0.59      0.65       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_predictions = np.full_like(y_multilabel_test_predict, -1)\n",
    "\n",
    "\n",
    "non_toxic_indices = np.argwhere(y_binary_test_predict == 0).flatten()\n",
    "toxic_indices = np.argwhere(y_binary_test_predict == 1).flatten()\n",
    "\n",
    "# place binary classifier's prediction of clean comments\n",
    "final_predictions[non_toxic_indices] = np.array([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "multilabel_toxic_predictions = y_multilabel_test_predict[toxic_indices]\n",
    "final_predictions[toxic_indices] = multilabel_toxic_predictions\n",
    "\n",
    "print(classification_report(y_multilabel_test, final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_param_grid = {\n",
    "        'bag_of_words__stop_words': ['english'],\n",
    "        'bag_of_words__ngram_range': [(1, 2)],\n",
    "        'bag_of_words__max_features': [500],\n",
    "        'dim_reduct__n_components': [300],\n",
    "        'normalizer__norm': ['l2'],\n",
    "        'classifier__max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "multilabel_param_grid = [{\n",
    "        'estimator__bag_of_words__stop_words': ['english'],\n",
    "        'estimator__bag_of_words__ngram_range': [(1, 2)],\n",
    "        'estimator__bag_of_words__max_features': [500],\n",
    "        'estimator__dim_reduct__n_components': [300],\n",
    "        'estimator__normalizer__norm': ['l2'],\n",
    "        'estimator__classifier__max_depth': [5, 10, 15]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.35      0.41        17\n",
      "          1       0.39      0.54      0.45        13\n",
      "\n",
      "avg / total       0.45      0.43      0.43        30\n",
      "\n",
      "'=================     Best parameters     ================='\n",
      "{'bag_of_words__max_features': 500, 'bag_of_words__ngram_range': (1, 2), 'bag_of_words__stop_words': 'english', 'classifier__max_depth': 15, 'dim_reduct__n_components': 300, 'normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "binary_clf = run_binary_classifier.run(binary_param_grid, DecisionTreeClassifier(), comments_file=train_binary)\n",
    "\n",
    "with open('./saved_models/dec_tree_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.33      0.12      0.18         8\n",
      "          2       0.89      0.73      0.80        22\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.60      0.25      0.35        24\n",
      "          5       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.76      0.60      0.65        88\n",
      "\n",
      "=================     Best parameters     =================\n",
      "{'estimator__bag_of_words__max_features': 500,\n",
      " 'estimator__bag_of_words__ngram_range': (1, 2),\n",
      " 'estimator__bag_of_words__stop_words': 'english',\n",
      " 'estimator__classifier__max_depth': 5,\n",
      " 'estimator__dim_reduct__n_components': 300,\n",
      " 'estimator__normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.6s finished\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\jasmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "multilabel_clf = run_multilabel_classifier.run(multilabel_param_grid, DecisionTreeClassifier(), comments_file=train_multilabel)\n",
    "with open('./saved_models/dec_tree_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.43      0.47        51\n",
      "          1       0.50      0.59      0.54        49\n",
      "\n",
      "avg / total       0.51      0.51      0.51       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_binary_test, y_binary_test = run_binary_classifier.load_comments(test_binary)\n",
    "y_binary_test_predict = binary_clf.predict(X_binary_test)\n",
    "\n",
    "print(classification_report(y_binary_test, y_binary_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       100\n",
      "          1       0.21      0.30      0.25        10\n",
      "          2       0.78      0.67      0.72        63\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.65      0.60      0.63        60\n",
      "          5       0.25      0.17      0.20        12\n",
      "\n",
      "avg / total       0.78      0.73      0.75       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_multilabel_test, y_multilabel_test = run_multilabel_classifier.load_comments(test_multilabel)\n",
    "y_multilabel_test_predict = multilabel_clf.predict(X_multilabel_test)\n",
    "\n",
    "print(classification_report(y_multilabel_test, y_multilabel_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final joint prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.73       100\n",
      "          1       0.12      0.10      0.11        10\n",
      "          2       0.88      0.37      0.52        63\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.61      0.28      0.39        60\n",
      "          5       0.25      0.17      0.20        12\n",
      "\n",
      "avg / total       0.79      0.41      0.53       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_predictions = np.full_like(y_multilabel_test_predict, -1)\n",
    "\n",
    "\n",
    "non_toxic_indices = np.argwhere(y_binary_test_predict == 0).flatten()\n",
    "toxic_indices = np.argwhere(y_binary_test_predict == 1).flatten()\n",
    "\n",
    "# place binary classifier's prediction of clean comments\n",
    "final_predictions[non_toxic_indices] = np.array([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "multilabel_toxic_predictions = y_multilabel_test_predict[toxic_indices]\n",
    "final_predictions[toxic_indices] = multilabel_toxic_predictions\n",
    "\n",
    "print(classification_report(y_multilabel_test, final_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
