{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import run_binary_classifier\n",
    "import run_multilabel_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary = os.path.join('../../../', 'data/train_binary.csv')\n",
    "test_binary = os.path.join('../../../', 'data/test_clean_binary.csv')\n",
    "\n",
    "train_multilabel = os.path.join('../../../', 'data/train.csv')\n",
    "test_multilabel = os.path.join('../../../', 'data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_param_grid = {\n",
    "        'bag_of_words__stop_words': ['english'],\n",
    "        'bag_of_words__ngram_range': [(1, 2)],\n",
    "        'bag_of_words__max_features': [500],\n",
    "        'dim_reduct__n_components': [300],\n",
    "        'normalizer__norm': ['l2'],\n",
    "        'classifier__C': [5., 10.]\n",
    "}\n",
    "\n",
    "\n",
    "multilabel_param_grid  = [{\n",
    "        'estimator__bag_of_words__stop_words': ['english'],\n",
    "        'estimator__bag_of_words__ngram_range': [(1, 2)],\n",
    "        'estimator__bag_of_words__max_features': [500],\n",
    "        'estimator__dim_reduct__n_components': [300],\n",
    "        'estimator__normalizer__norm': ['l2'],\n",
    "        'estimator__classifier__C': [5., 10.]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.73      0.71        15\n",
      "          1       0.71      0.67      0.69        15\n",
      "\n",
      "avg / total       0.70      0.70      0.70        30\n",
      "\n",
      "'=================     Best parameters     ================='\n",
      "{'bag_of_words__max_features': 500, 'bag_of_words__ngram_range': (1, 2), 'bag_of_words__stop_words': 'english', 'classifier__C': 5.0, 'dim_reduct__n_components': 300, 'normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "binary_clf = run_binary_classifier.run(binary_param_grid, LogisticRegression(), comments_file=train_binary)\n",
    "\n",
    "with open('./saved_models/log_reg_joint_binary.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 3 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.11554632, 0.11701474]),\n",
      " 'mean_score_time': array([0.00883236, 0.00886106]),\n",
      " 'mean_test_score': array([0.45714286, 0.42857143]),\n",
      " 'mean_train_score': array([0.78928571, 0.95714286]),\n",
      " 'param_estimator__bag_of_words__max_features': masked_array(data=[500, 500],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_estimator__bag_of_words__ngram_range': masked_array(data=[(1, 2), (1, 2)],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_estimator__bag_of_words__stop_words': masked_array(data=['english', 'english'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_estimator__classifier__C': masked_array(data=[5.0, 10.0],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_estimator__dim_reduct__n_components': masked_array(data=[300, 300],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_estimator__normalizer__norm': masked_array(data=['l2', 'l2'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'estimator__bag_of_words__max_features': 500,\n",
      "             'estimator__bag_of_words__ngram_range': (1, 2),\n",
      "             'estimator__bag_of_words__stop_words': 'english',\n",
      "             'estimator__classifier__C': 5.0,\n",
      "             'estimator__dim_reduct__n_components': 300,\n",
      "             'estimator__normalizer__norm': 'l2'},\n",
      "            {'estimator__bag_of_words__max_features': 500,\n",
      "             'estimator__bag_of_words__ngram_range': (1, 2),\n",
      "             'estimator__bag_of_words__stop_words': 'english',\n",
      "             'estimator__classifier__C': 10.0,\n",
      "             'estimator__dim_reduct__n_components': 300,\n",
      "             'estimator__normalizer__norm': 'l2'}],\n",
      " 'rank_test_score': array([1, 2], dtype=int32),\n",
      " 'split0_test_score': array([0.5       , 0.35714286]),\n",
      " 'split0_train_score': array([0.80357143, 0.94642857]),\n",
      " 'split1_test_score': array([0.35714286, 0.5       ]),\n",
      " 'split1_train_score': array([0.76785714, 0.96428571]),\n",
      " 'split2_test_score': array([0.5, 0.5]),\n",
      " 'split2_train_score': array([0.78571429, 0.96428571]),\n",
      " 'split3_test_score': array([0.57142857, 0.42857143]),\n",
      " 'split3_train_score': array([0.78571429, 0.94642857]),\n",
      " 'split4_test_score': array([0.35714286, 0.35714286]),\n",
      " 'split4_train_score': array([0.80357143, 0.96428571]),\n",
      " 'std_fit_time': array([0.01535734, 0.00979879]),\n",
      " 'std_score_time': array([0.00100794, 0.00120252]),\n",
      " 'std_test_score': array([0.08571429, 0.06388766]),\n",
      " 'std_train_score': array([0.01336306, 0.00874818])}\n",
      "=================  Classification report  =================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        30\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.50      0.75      0.60        12\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.67      0.67      0.67        12\n",
      "          5       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.76      0.81      0.78        58\n",
      "\n",
      "=================     Best parameters     =================\n",
      "{'estimator__bag_of_words__max_features': 500,\n",
      " 'estimator__bag_of_words__ngram_range': (1, 2),\n",
      " 'estimator__bag_of_words__stop_words': 'english',\n",
      " 'estimator__classifier__C': 5.0,\n",
      " 'estimator__dim_reduct__n_components': 300,\n",
      " 'estimator__normalizer__norm': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "multilabel_clf = run_multilabel_classifier.run(multilabel_param_grid, LogisticRegression(), comments_file=train_multilabel)\n",
    "with open('./saved_models/log_reg_joint_multilabel.pkl', 'wb') as saved_model:\n",
    "\tpickle.dump(binary_clf, file=saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.82      0.77        50\n",
      "          1       0.79      0.68      0.73        50\n",
      "\n",
      "avg / total       0.75      0.75      0.75       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_binary_test, y_binary_test = run_binary_classifier.load_comments(test_binary)\n",
    "y_binary_test_predict = binary_clf.predict(X_binary_test)\n",
    "\n",
    "print(classification_report(y_binary_test, y_binary_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       100\n",
      "          1       0.20      0.14      0.17         7\n",
      "          2       0.62      0.78      0.69        59\n",
      "          3       0.00      0.00      0.00         7\n",
      "          4       0.59      0.64      0.62        50\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.71      0.76      0.74       235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_multilabel_test, y_multilabel_test = run_multilabel_classifier.load_comments(test_multilabel)\n",
    "y_multilabel_test_predict = multilabel_clf.predict(X_multilabel_test)\n",
    "\n",
    "print(classification_report(y_multilabel_test, y_multilabel_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final joint prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.43      0.60       100\n",
      "          1       0.25      0.14      0.18         7\n",
      "          2       0.56      0.31      0.40        59\n",
      "          3       0.00      0.00      0.00         7\n",
      "          4       0.46      0.26      0.33        50\n",
      "          5       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.67      0.32      0.43       235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zvonimir/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "final_predictions = np.full_like(y_multilabel_test_predict, -1)\n",
    "\n",
    "\n",
    "non_toxic_indices = np.argwhere(y_binary_test_predict == 0).flatten()\n",
    "toxic_indices = np.argwhere(y_binary_test_predict == 1).flatten()\n",
    "\n",
    "# place binary classifier's prediction of clean comments\n",
    "final_predictions[non_toxic_indices] = np.array([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "multilabel_toxic_predictions = y_multilabel_test_predict[toxic_indices]\n",
    "final_predictions[toxic_indices] = multilabel_toxic_predictions\n",
    "\n",
    "print(classification_report(y_multilabel_test, final_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
